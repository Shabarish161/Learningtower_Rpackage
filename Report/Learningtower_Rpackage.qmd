---
title: "Report of developing Learningtower R package"
author:
- name: Shabarish Sai Subramanian
  degrees: Master of Businss Analytics
  email: shab0011@student.monash.edu
- name: Guan Ru, Chen
  degrees: Master of Businss Analytics
  email: gche0054@student.monash.edu
phone: (03) 9905 2478
email: BusEco-Econometrics@monash.edu
organization: Department of Econometrics & Business Statistics, Monash University
bibliography: references.bib
format: report-pdf
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE)
```

```{r loadlibraries}
library(here)
library(brolgar)
library(rjtools)
library(learningtower)
library(tidyverse)
library(ggplot2)
library(viridis)
library(dplyr)
library(patchwork)
library(plotly)
library(ggbeeswarm)
library(gghighlight)
library(ggrepel)
```

```{r datasets}
student_2022_full <- readRDS("../Data/student_2022.rds")
load("../data/countrycode.rda")
load("../data/student.rda")
load("../data/student_data_2018_2022.rda")
load("../data/math_diff_conf_intervals.rda")
load("../data/read_diff_conf_intervals.rda")
load("../data/sci_diff_conf_intervals.rda")
load("../data/father_qual_math_read_sci_data.rda")
load("../data/mother_qual_math_read_sci_data.rda")
load("../data/int_math_read_sci_data.rda")
load("../data/comp_math_read_sci_data.rda")

student_country <- left_join(student_2022_full,
                             countrycode, by = "country")
```
# Abstract

# Background

The learningtower package, which focusses on school and student-level data like performance indicators, socioeconomic backgrounds, and educational resources, contains educational datasets from international exams like PISA before 2022. After being cleaned and standardised, these datasets go through modifications including variable alignment for consistency and student-teacher ratio calculations. Key performance indicators include student performance in disciplines including reading, mathematics, and science; school and country identities; and educational resources (e.g., staff shortages, school size). The information makes it possible to analyse regional and worldwide trends as well as differences in educational systems, which sheds light on the variables influencing resource allocation and academic performance.

# Introduction

A potent tool for analysing global educational data, the learningtower program focusses on Programme for International Student Assessment (PISA) statistics gathered over a number of years. These databases include precise school and student-level statistics from several nations, including student achievement in areas like reading, mathematics, and science, as well as contextual aspects like school resources, teacher-student ratios, and socioeconomic backgrounds. In order to make data from prior years (before 2022) appropriate for comprehensive cross-sectional and longitudinal investigations, the package makes sure that the data is cleaned, standardised, and converted to maintain consistency. With the help of this preparation, users can investigate worldwide trends in education, spot inequalities, and evaluate how various factors affect student achievements. We are now integrating the 2022 dataset, which has been effectively configured inside the package, guaranteeing that it is prepared for examination. With this update, the package can now offer the most accurate and up-to-date insights into global educational trends, allowing for greater cross-country comparison and analysis.

## PISA

The Organization for Economic Cooperation and Development [OECD](https://www.oecd.org/about/) is a global organization that aims to create better policies for better lives. Its mission is to create policies that promote prosperity, equality, opportunity, and well-being for all. [@oecd] [PISA](https://www.oecd.org/pisa/) is one of OECD's Programme for International Student Assessment. PISA assesses 15-year-old students' potential to apply their knowledge and abilities in reading, mathematics, and science to real-world challenges. OECD launched this in 1997, it was initially administered in 2000, and it currently includes over [80 nations](https://www.oecd.org/pisa/aboutpisa/pisa-participants.html). [@pisa] The PISA study, conducted every three years, provides comparative statistics on 15-year-old students' performance in reading, math, and science. This report describes how to utilize the `learningtower` package, which offers OECD PISA datasets from 2000 to 2022 in an easy-to-use format. The datasets comprise information on students' test results and other socioeconomic factors, as well as information on their schools, infrastructure and the countries participating in the program.

## Learningtower Package

['learningtower'](https://cran.r-project.org/web/packages/learningtower/index.html) The R package [@learningtower] provides quick access to a variety of variables in the OECD PISA data collected over a three-year period from 2000 to 2022. This dataset includes information on the PISA test scores in mathematics, reading, and science. Furthermore, these datasets include information on other socioeconomic aspects, as well as information on their school and its facilities, as well as the nations participating in the program.

The `learningtower` package primarily comprised of three datasets: `student`, `school`, and `countrycode.` The `student` dataset includes results from triennial testing of 15-year-old students throughout the world. This dataset also includes information about their parents' education, family wealth, gender, and presence of computers, internet, vehicles, books, rooms, desks, and other comparable factors. Due to the size limitation on CRAN packages, only a subset of the student data can be made available in the downloaded package. These subsets of the student data, known as the `student_subset_yyyy` (`yyyy` being the specific year of the study) allow uses to quickly load, visualise the trends in the full data. The full student dataset can be downloaded using the `load_student()` function included in this [package.](https://kevinwang09.github.io/learningtower/) The `school` dataset includes school weight as well as other information such as school funding distribution, whether the school is private or public, enrollment of boys and girls, school size, and similar other characteristics of interest of different schools these 15-year-olds attend around the world. The `countrycode` dataset includes a mapping of a country/region's ISO code to its full name.

# Goals

The motivation for developing the `learningtower` package was sparked by the announcement of the PISA 2018 results, which caused a collective wringing of hands in the Australian press, with headlines such as ["Vital Signs: Australia's slipping student scores will lead to greater income inequality"](https://theconversation.com/vital-signs-australias-slipping-student-scores-will-lead-to-greater-income-inequality-128301) and ["In China, Nicholas studied math 20 hours a week. In Australia, it's three"](https://www.smh.com.au/education/in-china-nicholas-studied-maths-20-hours-a-week-in-australia-it-s-three-20191203-p53ggv.html). That's when several academics from Australia, New Zealand, and Indonesia decided to make things easier by providing easy access to PISA scores as part of the [ROpenSci OzUnconf](https://ozunconf19.ropensci.org/), which was held in Sydney from December 11 to 13, 2019.

The data from this survey, as well as all other surveys performed since the initial collection in 2000, is freely accessible to the public. However, downloading and curating data across multiple years of the PISA study could be a time consuming task. As a result, we have made a more convenient subset of the data freely available in a new R package called `learningtower`, along with sample code for analysis.

`learningtower` developers are committed to providing R users with data to analyse PISA results every three years. Our package's future enhancements include updating the package every time additional PISA scores are announced. Note that, in order to account for post COVID-19 problems, OECD member nations and associates decided to postpone the PISA 2021 evaluation to 2022 and the PISA 2024 assessment to 2025.

# Compiling the data(more details about the process and problems faced)

We are responsible for the curation of the newest PISA study, year 2022. data on the participating students and schools were first downloaded from the PISA website, in either SPSS or SAS format. The data were read into an R environment. After some data cleaning and wrangling with the appropriate script, the variables of interest were re-categorised and saved as RDS files. One major challenge faced by the us was to ensure the consistency of variables over the years. However, several variables may be missing due to the reconstruction of questionnaires. For instance, a question regarding student's possession of desk is not recorded in 2022, but it was included in previous questionnaires, hence these variables were manually curated as an character variable in the output data. Another important issue we faced is a missing variable `WEALTH`, this variable used to be a good measurement of a student's socioeconomic status. But we also discovered a variable called `ESCS` (economic, social and cultural status). These final RDS file for each PISA year were then thoroughly vetted and made available in a separate [GitHub repository](https://github.com/kevinwang09/learningtower_masonry).

# Communication and Documentation Tools

Slack and Notion can be effectively utilized together to enhance team communication and documentation management. Slack serves as a real-time communication tool, allowing teams to quickly exchange information, discuss projects, and stay updated on tasks, making it ideal for team collaboration.

Notion, on the other hand, excels as a centralized workspace for recording and organizing important documents, such as meeting journals, project notes, and other key materials, ensuring that important information is organized and easily accessible.

By using Slack for dynamic conversations and Notion for structured documentation, teams can ensure seamless communication while maintaining an organized record of all important documents, meeting notes, and long-term planning.

# Overview of the data

## Student Dataset

The dataset offers student-level information from a number of nations and captures variables that affect academic performance. it contains the 23 variables, which could be categorized into groups:

**Year**\*: represents the year of data collection, which is manually constructed by the contributor.

**Country**: specifies the country from which the student data has been collected, using country codes.

**School's inforamtion**: represents the unique identifier of each student's school.

**Student's inforamtion**: This group provides some information about each student in the dataset.

1.  **Parent's education**: record the parent’s highest level of education based on the International Standard Classification of Education (ISCED) levels, ranging from "less than ISCED1" to "ISCED 3B, C".

2.  **Gender**: categorizes the gender of each student as "male" or "female".

3.  **Household possession**: record several variables related to students' household resources. Including whether the student has access to a computer and internet at home, both marked as "yes" or "no." Additional household resources are indicated by variables for a desk, separate room, dishwasher, television, and car. The number of computers and laptops is also available. Finally, the number of books in the student's home is categorized into ranges, such as "0-10" or "101-200.

4.  **Math, Read, Science**: These columns provide the scores in mathematics, reading, and science subjects, respectively.

5.  **Stu_Wgt**: Represents the student weight, used for calculating weighted averages in the analysis to ensure representative data.

6.  **Wealth**: This column provides a measure of the student's economic wealth, where higher values indicate greater wealth. However this variable is not recorded in 2022 dataset.

7.  **ESCS**: Represents the Economic, Social, and Cultural Status index, which is a composite measure of a student's socio-economic background.


## School Dataset

The dataset includes school weight as well as other information such as school funding distribution, whether the school is private or public, enrollment of boys and girls, school size, and similar other characteristics of interest of different schools these 15-year-olds attend around the world.
```{r}
data("school")
head(school)
```
**Year***: represents the year of data collection, which is manually constructed by the contributor.

**Country**: specifies the country from which the student data has been collected, using country codes.

**School's information**: This group provides some information about each school in the dataset.

## Countrycode Dataset

This dataset includes a mapping of a country/region’s ISO code to its full name. More information on the participating countries can be found [here](https://www.oecd.org/en/about/programmes/pisa/pisa-participants.html).


# Analysis

In this section we will illustrate how the `Learningtower` package can be utilized to answer some research questions by applying various methodologies and statistical computations on the `Learningtower` datasets.

We will solely utilize the 2022 PISA data and scores for illustrative purposes throughout the analysis section. Some of these questions include if there is any significant gender difference between girls and boys and explore their performance in the areas of mathematics, reading, and science. Furthermore, we will inspect the various socioeconomic characteristics reflected in the student data and investigate if they have any substantial impact on the scores of these students. 

## Gender Gap
Gender gaps have always been a topic of interest among researchers, and when it comes to PISA data and scores of 15-year-old students around the world, uncovering patterns based on their gender would help gain meaningful insights in the field of education for various education policymakers around the world. Based on the 2022 PISA results, let us see if there is a major gender disparity between girls and boys throughout the world in mathematics, reading, and science. To begin, we will create a 'data.frame' that stores the weighted average math score for each nation as well as the various regions of the countries grouped by country and gender, in order to create this `data.frame` and represent data in the tidy format we use the `tidyverse` [@tidyverse] and `dplyr` [@dplyr] R packages. [Survey weights](https://www.oecd-ilibrary.org/education/pisa-2022-technical-report_01820d6d-en) are critical and must be used in the analysis to guarantee that each sampled student accurately represents the total number of pupils in the PISA population. In addition, we compute the gender difference between the two averages. To demonstrate the variability in the mean estimate, we use bootstrap sampling with replacement using the `map_dfr` function on the data and compute the same mean difference estimate. For each country, the empirical 90 percent confidence intervals are presented. The same process is used for reading and science test scores.

```{r}
math_plot <- ggplot(math_diff_conf_intervals,
                    aes(diff, country_name,
                        col = score_class)) +
  scale_colour_manual("",
      values = c("boys"="#3288bd",
                 "nodiff"="#969696",
                 "girls"="#f46d43")) +
  geom_point() +
  geom_errorbar(aes(xmin = lower, xmax = upper), width=0) +
  geom_vline(xintercept = 0, color = "#969696") +
  labs(y = "",
  x = "",
  title = "Math"
  ) +
  theme(legend.position="none") +
  annotate("text", x = 50, y = 1, label = "Girls") +
  annotate("text", x = -50, y = 1, label = "Boys") +
  scale_x_continuous(limits = c(-70, 70),
                     breaks = seq(-60, 60, 20),
                     labels = abs(seq(-60, 60, 20)))
```
```{r read plot}
read_plot <- ggplot(read_diff_conf_intervals,
                    aes(diff, country_name,
                        col = score_class)) +
  scale_colour_manual("",
      values = c("boys"="#3288bd",
                 "nodiff"="#969696",
                 "girls"="#f46d43")) +
  geom_point() +
  geom_errorbar(aes(xmin = lower, xmax = upper), width=0) +
  geom_vline(xintercept = 0, color = "#969696") +
  labs(y = "",
  x = "",
  title = "Reading"
  ) +
  theme(legend.position="none") +
  annotate("text", x = 50, y = 1, label = "Girls") +
  annotate("text", x = -50, y = 1, label = "Boys") +
  scale_x_continuous(limits = c(-70, 70),
                     breaks = seq(-60, 60, 20),
                     labels = abs(seq(-60, 60, 20)))
```

```{r science plot}
sci_plot <- ggplot(sci_diff_conf_intervals,
                    aes(diff, country_name,
                        col = score_class)) +
  scale_colour_manual("",
      values = c("boys"="#3288bd",
                 "nodiff"="#969696",
                 "girls"="#f46d43")) +
  geom_point() +
  geom_errorbar(aes(xmin = lower, xmax = upper), width=0) +
  geom_vline(xintercept = 0, color = "#969696") +
  labs(y = "",
  x = "",
  title = "Science"
  ) +
  theme(legend.position="none") +
  annotate("text", x = 50, y = 1, label = "Girls") +
  annotate("text", x = -50, y = 1, label = "Boys") +
  scale_x_continuous(limits = c(-70, 70),
                     breaks = seq(-60, 60, 20),
                     labels = abs(seq(-60, 60, 20)))
```
```{r}
#| label: fig-diff
#| fig-cap: "The chart above depicts the gender gap difference in 15-year-olds' in math, reading, and science results in 2022. The scores to the right of the grey line represent the performances of the girls, while the scores to the left of the grey line represent the performances of the boys. One of the most intriguing conclusions we can get from this chart is that in the PISA experiment in 2022, girls from all countries outperformed boys in reading.The chart above depicts the gender gap difference in 15-year-olds' in math, reading, and science results in 2022. The scores to the right of the grey line represent the performances of the girls, while the scores to the left of the grey line represent the performances of the boys. One of the most intriguing conclusions we can get from this chart is that in the PISA experiment in 2022, girls from all countries outperformed boys in reading."
#| fig-width: 11
#| fig-height: 11
#| fig-pos: "H"
#| out-width: "100%"

math_plot + read_plot + sci_plot
```
@fig-diff illustrates the global disparities in mean math, reading, and science outcomes, before we get to the plot conclusion, let's have a look at the variables that have been plotted. The grey line here indicates a reference point, and all of the scores to the right of the grey line show the scores of girls in math, reading, and science. Similarly, the scores on the left side of this grey line indicate the scores of boys in the three disciplines. Based on @fig-diff, because most math estimates and confidence intervals lie to the left of the grey line, we may conclude that most boys outperformed girls in math. 

In nations such as Panama, Malta, Saudi Arabia, Sweden, Kazakhstan, Norway, Slovenia, Iceland, Kosovo, Cambodia, Montenegro and Slovakia, there is almost no gender difference in average math scores. When we look at the reading scores, we notice a remarkable trend in that all girls outpaced boys in reading in all countries in 2022. The highest reading scores were achieved by girls from Palestine, Jordan and United Arab Emirates. Looking further into the science plot, we see an unexpected pattern here where most countries have very little gender difference in science scores, implying that most boys and girls perform equally well in science. Boys from Costa Rica, Mexico and and Peru perform well in science and girls from Jordan, Palestine, and Albania are the top scores for science. @fig-diff helps us to depict the gender gap in math, reading, and science for all nations and regions that took part in the 2022 PISA experiment.

We gathered meaningful insights about the gender gap between girls and boys across the world from the above @fig-diff because this is a geographical research communication topic, the findings will help us better comprehend the score differences in the three educational disciplines using world maps. Let us continue to investigate and discover patterns and correlations using map visualization. To illustrate the gender gap difference between girls and boys throughout the world, we summarize regions on a country level and utilize the `map_data` function to get the latitude and longitude coordinates needed to construct a map for our data. We connect these latitude and longitude coordinates to our PISA data and render the world map using the `geom_polygon` function wrapped within `ggplot2` [@ggplot2], the interactive features and placement of the plots are made using `plotly` [@plotly] and `patchwork` [@patchwork] packages in R.

```{r}
theme_map <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(),
    axis.line = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.border = element_blank(),
    panel.grid = element_blank()
  )
}

region2country = function(region_name){
  country_name = case_when(
    region_name == "Brunei Darussalam" ~ "Brunei",
    region_name == "United Kingdom" ~ "UK",
    region_name %in% c("Macau SAR China", "B-S-J-Z (China)",
                        "Hong Kong SAR China") ~ "China",
    region_name == "Korea" ~ "South Korea",
    region_name == "North Macedonia" ~ "Macedonia",
    region_name == "Baku (Azerbaijan)" ~ "Baku",
    region_name %in% c("Moscow Region (RUS)", "Tatarstan (RUS)",
                        "Russian Federation") ~ "Russia",
    region_name == "Slovak Republic" ~ "Slovakia",
    region_name == "Chinese Taipei" ~ "Taiwan",
    region_name == "United States" ~ "USA",
    TRUE ~ as.character(region_name))
}
```

```{r}
math_map_data <- math_diff_conf_intervals  %>%
  dplyr::mutate(country_name = region2country(region_name = country_name))

world_map <- map_data("world") %>%
  filter(region != "Antarctica") %>%
  fortify() %>%
  rename(country_name = region)

math_world_data <- full_join(
  x = math_map_data,
  y = world_map,
  by = "country_name") %>% 
  rename(Country = country_name,
         math = diff) %>%
  mutate(math = round(math, digits = 2))
```

```{r}
read_map_data <- read_diff_conf_intervals %>%
  dplyr::mutate(country_name = region2country(region_name = country_name))

world_map <- map_data("world") %>%
  filter(region != "Antarctica") %>%
  fortify() %>%
  rename(country_name = region)

read_world_data <- full_join(
  x = read_map_data,
  y = world_map,
  by = "country_name") %>% 
  rename(Country = country_name,
         Reading = diff) %>%
  mutate(Reading = round(Reading, digits = 2))
```

```{r}
sci_map_data <- sci_diff_conf_intervals %>%
  dplyr::mutate(country_name = region2country(region_name = country_name))

world_map <- map_data("world") %>%
  filter(region != "Antarctica") %>%
  fortify() %>%
  rename(country_name = region)

sci_world_data <- full_join(
  x = sci_map_data,
  y = world_map,
  by = "country_name") %>% 
  rename(Country = country_name,
         Science = diff)  %>%
  mutate(Science = round(Science, digits = 2))

math_dat <- math_world_data %>%
  dplyr::select(Country, math, lat, long, group)

read_dat <- read_world_data %>%
  dplyr::select(Country, Reading, lat, long, group)

sci_dat <- sci_world_data %>%
  dplyr::select(Country, Science, lat, long, group)

math_read_dat <- left_join(math_dat,
                           read_dat,
                           by = c("Country","lat", "long", "group"))

math_read_sci_dat <- left_join(math_read_dat,
                           sci_dat,
                           by = c("Country","lat", "long", "group"))

math_read_sci_dat_wider <- math_read_sci_dat %>%
    pivot_longer(cols = c(2,6,7), names_to = "subjects")

mrs_maps <- ggplot(math_read_sci_dat_wider,
       aes(x = long,
           y = lat,
           group = group)) +
  geom_polygon(aes(fill= value,
                   label = Country)) +
  facet_wrap(~subjects, scales = "free", nrow = 3) +
  theme_map() +
  labs(title = "World Map displaying Gender Gap Scores in Math, Reading and Science")  +
  scale_fill_distiller(palette = "Spectral")
```

```{r}
#| label: fig-worldmaps
#| fig-cap: "Maps showing the gender gap in math, reading, and science results between girls and boys across the world. A positive score for a country indicates that girls outperformed boys in that country, whereas a negative score for a country difference indicates that boys outperformed girls in that country. The diverging colour scale makes it possible to interpret the range of scores and the also helps us intrepret the gender gap difference among these students across the globe."
#| fig-pos: "H"
#| out-width: "100%"

mrs_maps
```
In the @fig-worldmaps, we have shown the gender gap difference between girls and boys in math, reading, and science in 2022. Map visualization aids in the comprehension of large volumes of data in a more efficient manner and increases the ability to compare outcomes across many geographical locations at a glance. In this figure, we see both positive and negative score difference scale ranges in all three maps. A positive country score indicates that girls outperformed boys in that country, whereas a negative country score shows that boys outscored girls in that country. The diverging spectral color scale and the legend of these maps makes it possible for us to deduce and identify regions across the globe showing large gender discrepancy between girls and boys. The grey colour for different geographic locations across the maps in @fig-worldmaps indicates that these regions were not a part of the PISA experiment in year 2022. 

Even though the map visualization embeds the same scores as @fig-worldmaps, one of the most striking thing on this map is the lack of data for the Africa continent. We see that there is less of a gender disparity seen in the science scores compared to maths and reading. In addition, the color scale for scores of each subject aids in identifying the countries that took part in the PISA experiment. As a result, in this section, we have seen the gender gap scores and striking trends between 15-year-old girls and boys in math, reading, and science. Our main conclusion from this gender study is the performance of girls in reading. The fewer gender disparity is evident in the science scores, and the majority of boys perform better than girls in mathematics.

## EcoSocio factors

```{r}
p1 <- ggplot(data = student_country,
             aes(x = math, y = read)) +
  geom_hex() +
  labs(x = "Math Scores",
       y = "Reading Scores") +
  theme(legend.position="none")

p2 <- ggplot(data = student_country,
             aes(x = math, y = science)) +
  geom_hex() +
  labs(x = "Math Scores",
       y = "Science Scores") +
  theme(legend.position = "none")

p3 <- ggplot(data = student_country,
             aes(x = read, y = science)) +
  geom_hex() +
  labs(x = "Reading Scores",
       y = "Science Scores") +
  theme(legend.position="none")
```

```{r}
#| label: fig-corrplot
#| fig-cap: "The scatterplot displays the relationship between math, reading, and science scores for all PISA countries that participated in the experiment in 2022. This scatterplot shows that all three subjects have a significant and positive correlation with one another."
#| fig-width: 9
#| fig-pos: "H"
#| out-width: "100%"
p1+p2+p3
```

```{r}
father_qual_math_read_sci_data <- student_country %>%
  group_by(country_name, father_educ) %>%
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>%
  dplyr::mutate(father_educ = recode_factor(father_educ,
                "less than ISCED1" = "Early Childhood",
                "ISCED 1" = "Primary",
                "ISCED 2" = "Lower Secondary",
                "ISCED 3A" = "Upper Secondary",
                "ISCED 3B, C" = "Upper Secondary",
                .ordered = TRUE)) %>%
  na.omit() %>%
  rename(`Father's Education` = father_educ)

mother_qual_math_read_sci_data <- student_country %>%
  group_by(country_name, mother_educ) %>%
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>%
  dplyr::mutate(mother_educ = recode_factor(mother_educ,
                "less than ISCED1" = "Early Childhood",
                "ISCED 1" = "Primary",
                "ISCED 2" = "Lower Secondary",
                "ISCED 3A" = "Upper Secondary",
                "ISCED 3B, C" = "Upper Secondary",
                .ordered = TRUE)) %>%
  na.omit() %>%
  rename(`Mother's Education` = mother_educ)

mother_qual_math <- ggplot(mother_qual_math_read_sci_data,
       aes(x=`Mother's Education`,
           y=math_avg)) +
  geom_quasirandom(size = 1.7,
             cex = 3) +
  geom_line(aes(group = country_name),
            size=0.5, alpha=.36) +
  scale_fill_viridis(discrete = TRUE,
                     option = "A",
                      alpha=0.2) +
    stat_summary(fun.y = median,
                 fun.ymin = median,
                 fun.ymax = median,
                 geom = "crossbar",
                 width = 0.5,
                 col = "black") +
  theme(legend.position="none",
      plot.title = element_text(size=11)) +
  labs(y = "Average Mathematics Score",
       x = "Mother's Qualification",
       title = "math Scores and Mother's Qualification")

father_qual_math <- ggplot(father_qual_math_read_sci_data,
       aes(x=`Father's Education`,
           y=math_avg)) +
  geom_quasirandom(size = 1.7,
             cex = 3) +
  geom_line(aes(group = country_name),
            size=0.5, alpha=.36) +
  scale_fill_viridis(discrete = TRUE,
                     option = "A",
                      alpha=0.2) +
    stat_summary(fun.y = median,
                 fun.ymin = median,
                 fun.ymax = median,
                 geom = "crossbar",
                 width = 0.5,
                 col = "black") +
  theme(legend.position="none",
      plot.title = element_text(size=11)) +
  labs(y = "Average Mathematics Score",
       x = "Father's Qualification",
       title = "math Scores and Father's Qualification")
```

```{r}
#| label: fig-qualplot
#| fig-cap: "The impact of parents' education on their children's academic progress is depicted in this graph. When the parents have greater levels of education, we see a considerable rise in scores and an increase in the median of scores for each category, as shown in the figure. In comparison to parents with lower levels of education qualifications. Parents who have tend to have upper secondary qualification or equivalent credentials their children are more likely to perform better in academics when compared with parent having lesser levels of qualifications."
#| fig-width: 15
#| fig-height: 8
#| fig-pos: "H"
#| out-width: "100%"

father_qual_math + mother_qual_math
```

```{r}
z_star_95 <- qnorm(0.975)

tv_math_data <- student_country %>%
  group_by(country_name, television) %>%
  dplyr::summarise(math_avg =
                     weighted.mean(math,
                                   w = stu_wgt,
                                   na.rm = TRUE),
                   lower = weighted.mean(math,
                      w = stu_wgt, na.rm = TRUE) -
                      z_star_95 * (sd(math, na.rm = TRUE)) /
                      sqrt(length(math)),
                   upper = weighted.mean(math,
                      w = stu_wgt, na.rm = TRUE) +
                      z_star_95 * (sd(math, na.rm = TRUE)) /
                     sqrt(length(math)),
                   .groups = "drop") %>%
  dplyr::mutate(television = recode_factor(television,
                "0" = "No TV",
                "1" = "1 TVs",
                "2" = "2 Tvs",
                "3+" = "3+ TVs",
               .ordered = TRUE)) %>%
  na.omit() %>%
  dplyr::select(country_name,
                television,
                math_avg,
                lower,
                upper)

linear_model <- function(y, x){
  coef(lm(y ~ x))[2]
}

tv_plot <- tv_math_data %>%
  group_by(country_name) %>%
  mutate(slope = linear_model(math_avg, television)) %>%
  ungroup() %>%
  mutate(country_name = fct_reorder(country_name, slope)) %>%
  ggplot(aes(x=as.numeric(television), y=math_avg)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
                colour="orange", fill = "orange",
              alpha=0.45) +
  geom_point(size=1.8) +
  geom_line() +
  facet_wrap(~country_name, ncol = 8, scales = "free") +
#  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) +
  theme(axis.text = element_blank()) +
  labs(x = "Number of TVs",
       y = "Average Mathematics Score")
```

```{r}
#| label: fig-tvplot
#| fig-cap: "Relationship  between number of TVs in a household and average math scores across countries. Number of TVs ranges from 0 to 3 or more. The orange bands indicate 95 percent standard confidence intervals. The impact of television on student performance is a contentious issue. It is interesting that in some countries for example in South Korea's effect appears to be positive, but in other countries like Poland and Germany there is a decline in average math scores."
#| fig-width: 12
#| fig-height: 12
#| fig-pos: "H"
#| out-width: "100%"
tv_plot
```

```{r}
z_star_95 <- qnorm(0.975)

book_math_read_sci_data <- student_country %>%
  group_by(country_name, book)  %>%
  dplyr::summarise(math_avg =
            weighted.mean(math,
              w = stu_wgt, na.rm = TRUE),
           bk_lower = weighted.mean(math,
              w = stu_wgt, na.rm = TRUE) -
              z_star_95 * (sd(math, na.rm = TRUE)) /
              sqrt(length(math)),
           bk_upper = weighted.mean(math,
              w = stu_wgt, na.rm = TRUE) +
              z_star_95 * (sd(math, na.rm = TRUE)) /
              sqrt(length(math)), .groups = "drop")  %>%
  dplyr::mutate(book = recode_factor(book,
                                     "0-10" = "1",
                                     "11-25" = "11",
                                     "26-100" = "26",
                                     "101-200" = "101",
                                     "201-500" = "201",
                                     "more than 500" = "500",
                                     .ordered = TRUE)) %>%
  na.omit()

linear_model <- function(y, x){
  coef(lm(y ~ x))[2]
}


book_plot <- book_math_read_sci_data %>%
  group_by(country_name) %>%
  mutate(slope = linear_model(math_avg, book)) %>%
  ungroup() %>%
  mutate(country_name = fct_reorder(country_name, slope)) %>%
  ggplot(aes(x=as.numeric(book), y=math_avg)) +
  geom_ribbon(aes(ymin = bk_lower, ymax = bk_upper),
                colour="orange", fill="orange", alpha=0.45) +
  geom_point(size=1.8) +
  geom_line(aes(group = country_name)) +
  facet_wrap(~country_name, ncol = 8, scales = "free") +
  theme(axis.text = element_blank()) +
  labs(x = "Number of Books",
       y = "Average Mathematics Score")
```

```{r}
#| label: fig-bookplot
#| fig-cap: "Impact of the number of books on average math score. Number of books ranges from 0 to 500 and more. 95 percent standard confidence bands shown in orange. Math scores generally increase as the number of books increases. Averages for some countries at the higher number of books are less reliable, and hence the decline reflects more that there are few households with this many books than a true decline."
#| fig-width: 12
#| fig-height: 12
#| fig-pos: "H"
#| out-width: "100%"

book_plot
```

```{r}
int_math_read_sci_data <- student_country %>%
  group_by(country_name, internet) %>%
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>%
  na.omit()

comp_math_read_sci_data <- student_country %>%
  group_by(country_name, computer) %>%
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>%
  na.omit()


computer_plot <- comp_math_read_sci_data %>%
  ggplot(aes(x=computer,
             y= math_avg,
             group = country_name)) +
    geom_point(color = "black",
               size=0.36) +
    theme(legend.position = "none") +
    labs(x = "Possession of Computer",
         y = "Average Mathematics Score",
         title = "Impact of Computers on Average Math Scores")


internet_plot <- int_math_read_sci_data %>%
  ggplot(aes(x=internet,
             y= math_avg,
             group = country_name )) +
    geom_point(color = "black",
               size=0.36) +
    theme(legend.position = "none") +
    labs(x = "Access to Internet",
         y = "Average Mathematics Score",
         title = "Impact of Internet on Average Math Scores")
```

```{r}
#| label: fig-compintplot
#| fig-cap: "Computers and the Internet are two of the most important inventions in the history of technology. In this figure, we observe the impact of owning a computer and having access to the internet on 15-year-old students all over the world. A remarkable finding from the plot is that all nations have higher scores in student performance when they own a computer and have access to the internet."
#| fig-width: 8
#| fig-height: 4
#| fig-pos: "H"
#| out-width: "100%"
computer_plot + internet_plot
```



## Temporal Analysis


### Pandemic effects
```{r}
# Load student data, and filter to country, cache a copy of the data
# to save downloading every time paper is knitted

# if (!file.exists("data/student_all.rda")) {
#   student_all <- load_student("all")
#   save(student_all, file="data/student_all.rda")
# } else {
#   load("data/student_all.rda")
# }
student_all <- load(here("data/student.rda"))
# Give countries their name, subset to four, and select only variables needed
student_country <- left_join(student,
                             countrycode,
                             by = "country") %>%
  dplyr::filter(country_name %in%
                  c("Australia",
                    "Germany",
                    "Peru",
                    "Qatar",
                    "Belgium",
                    "Brazil",
                    "Denmark",
                    "Greece",
                    "Thailand",
                    "Singapore",
                    "Canada",
                    "Portugal")) %>%
  dplyr::select(year, country_name, math, read, science, stu_wgt) %>%
  na.omit() %>%
  pivot_longer(c(math, read, science), names_to = "subject", values_to = "score")

# Compute the bootstrap confidence intervals, and cache result
if (!file.exists("data/all_bs_cf.rda")) {
  all_bootstrap <- map_dfr(1:100, ~{
    student_country %>%
    group_by(country_name, #year,
             subject) %>%
    #sample_n(size = n(), replace = TRUE) %>%
    mutate(year = sample(year, replace=FALSE)) %>%
    group_by(country_name, year,
             subject) %>%
    dplyr::summarise(
      avg = weighted.mean(score, w = stu_wgt, na.rm = TRUE), .groups = "drop") %>%
    #ungroup() %>%
    mutate(boot_id = .x)
  })

  all_bootstrap_ci <- all_bootstrap %>%
    group_by(country_name, year,
             subject) %>%
    summarise(
      lower = min(avg), # sort(avg)[5],
      upper = max(avg), #sort(avg)[95],
      .groups = "drop")

  # compute original estimate of average and join
  all_avg <- student_country %>%
    group_by(country_name, year, subject) %>%
    summarise(
      avg = weighted.mean(score,
                          w = stu_wgt, na.rm = TRUE),
      .groups = "drop")

  all_bs_cf <- left_join(all_avg,
                      all_bootstrap_ci,
                      by = c("country_name",
                             "year",
                             "subject"))

  save(all_bs_cf, file= here("data/all_bs_cf.rda"))

} else {
  load(here("data/all_bs_cf.rda"))
}

```

```{r}
#| label: fig-bsplot
#| fig-cap: "Temporal patterns in math, reading, and science in a variety of countries. The highlighted countries in the chart help us infer Australia's performance in contrast to the other countries; we can see that Australia's scores have always been among the highest in the PISA survey throughout all years."
#| fig-width: 12
#| fig-height: 12
#| fig-pos: "H"
#| out-width: "100%"

all_bs_cf <- all_bs_cf %>%
  mutate(year = as.numeric(as.character(year)),
         country_name = factor(country_name))
                 # levels = c("Singapore",
                 #          "Australia",
                 #          "New Zealand",
                 #          "Germany",
                 #          "Qatar",
                 #          "Indonesia"))


country_names_highlight <- c("Australia", 
                             "Germany", 
                             "Peru", 
                             "Qatar", 
                             "Belgium", 
                             "Brazil", 
                             "Denmark", 
                             "Greece",
                             "Thailand", 
                             "Singapore", 
                             "Canada", 
                             "Portugal")

math_all_bs_cf_plot <- all_bs_cf %>% 
  dplyr::filter(subject == "math") %>% 
  ggplot(aes(x = year, 
             y = avg)) +
  geom_point(alpha = 0.45) +
  geom_line(aes(group = country_name)) +
  gghighlight::gghighlight(country_name %in% country_names_highlight) +
  labs(
    title = "Maths",
     x = "",
     y = "Score") 


read_all_bs_cf_plot <- all_bs_cf %>% 
  dplyr::filter(subject == "read") %>% 
  ggplot(aes(x = year, 
      y = avg)) +
  geom_point(alpha = 0.45) +
  geom_line(aes(group = country_name)) +
  gghighlight::gghighlight(country_name %in% country_names_highlight) +
  labs(
    title = "Reading",
     x = "",
     y = "Score") 

sci_all_bs_cf_plot <- all_bs_cf %>% 
  dplyr::filter(subject == "science") %>% 
  ggplot(aes(x = year, 
      y = avg)) +
  geom_point(alpha = 0.45) +
  geom_line(aes(group = country_name)) +
  gghighlight::gghighlight(country_name %in% country_names_highlight) +
  labs(
    title = "Science",
     x = "",
     y = "Score")


math_all_bs_cf_plot + read_all_bs_cf_plot + sci_all_bs_cf_plot
```

### Gender Gaps Across Subjects and Years

```{r}
#| fig-width: 18
#| fig-height: 12
#| echo: false

#calculating the weighted means for all three subjects and plotting them
w_mean = function(x, w){weighted.mean(x = x, w = w, na.rm=TRUE)}


stu_gender_summ  <-  student %>% 
  filter(complete.cases(gender)) %>% 
  group_by(year, country, gender) %>%
  summarise_at(.vars = vars(math, read, science), 
               .funs = list(wmean = ~w_mean(., w = stu_wgt))) %>% 
  mutate(year = year %>% as.character() %>% as.integer) %>% 
  group_by(country) %>%
  filter(n() >= 10) %>% 
  ungroup() %>% 
  pivot_longer(cols = contains("_wmean"),
               names_to = "names",
               values_to = "values") %>% 
  pivot_wider(names_from = c("gender", "names"),
              values_from = "values")

stu_ggap_summ  <-  stu_gender_summ %>% 
  dplyr::transmute(
    year, country,
    gap_math_wmean = female_math_wmean - male_math_wmean,
    gap_read_wmean = female_read_wmean - male_read_wmean,
    gap_science_wmean = female_science_wmean - male_science_wmean)


stu_ggap_summ_long  <-  stu_ggap_summ %>% 
  pivot_longer(cols = contains("gap"),
               names_to = "gap_names",
               values_to = "gap_values")

stu_ggap_summ_long %>%
  ggplot(aes(x = year, y = gap_values)) +
  geom_point() +
  geom_line(aes(group = country)) +
  geom_hline(yintercept = 0, colour = "red") +
  facet_wrap(~gap_names) +
  labs(title = "Average gender gaps across subjects and years", 
       subtitle = "Gap = avg. female score - avg. male score", 
       x = "Year", 
       y = "Gender Gap Values")
```

### Highlighting Key Countries


```{r}
#| fig-width: 12
#| fig-height: 6
#| echo: false
stu_ggap_summ_nest  <-  stu_ggap_summ %>%
  pivot_longer(contains("_wmean"),
               names_to = "names",
               values_to = "values") %>% 
  group_by(names) %>% 
  nest() %>% 
  mutate(f_tbl = map(.x = data, 
                     .f = ~ .x %>% 
                       as_tsibble(key = country, index = year) %>% 
                       features(values, feat_brolgar) %>% 
                       keys_near(key = country, var = range2)),
         f_data = map2(.x = data, .y = f_tbl, 
                       .f = ~ left_join(.x, .y, by = "country")))

stu_ggap_summ_plotdf  <-  stu_ggap_summ_nest %>% 
  select(names, f_data) %>% 
  unnest(f_data) %>% 
  left_join(countrycode, by = "country") %>% 
  mutate(label_stats_country = ifelse(is.na(stat), NA, paste0(stat, ":", country_name)))

stu_ggap_summ_plotdf %>% 
  ggplot(aes(x = year, y = values)) +
  geom_line(aes(group = country, colour = country)) +
  gghighlight(!is.na(stat), label_key = label_stats_country, calculate_per_facet = TRUE, keep_scales = TRUE) +
  facet_wrap(~names) + 
  labs(x = "Year",
       y = "Values", 
       title = "Highlighting key countries across all three subjects")
```

# Discussion

## Limitations

- Size limitation on CRAN packages: The data size would be bigger if keep uploading the newest data, so further curation process of data should be considered, or explore alternative data compression for the datasets.

- Variables Consistency: The construction of questionnaire would be different every survey, as well as the coding mechanism of the original dataset, so curation process must be examined everytime to ensure the consistency of variables.

# Conclusion

# Reference
 
## Git respository of the report

https://github.com/Shabarish161/Learningtower_Rpackage

